"""
å‹•ç”»æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«
- å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ æ–‡å­—èµ·ã“ã—
- æ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œ
- ãƒ†ã‚­ã‚¹ãƒˆ + SRTå½¢å¼ã§å‡ºåŠ›
"""

import streamlit as st
from faster_whisper import WhisperModel
import ffmpeg
import srt
import tempfile
import os
from datetime import timedelta
from pathlib import Path
import anthropic
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å‹•ç”»æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¬",
    layout="wide"
)

st.title("ğŸ¬ å‹•ç”»æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«")
st.markdown("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€æ—¥æœ¬èªãƒ»è‹±èªã®æ–‡å­—èµ·ã“ã—ãŒã§ãã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    model_option = st.selectbox(
        "Whisper ãƒ¢ãƒ‡ãƒ«",
        ["tiny", "base", "small", "medium"],
        index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ base
        help="tiny: æœ€é€Ÿãƒ»ä½ç²¾åº¦ / base: ãƒãƒ©ãƒ³ã‚¹å‹ / small: é«˜ç²¾åº¦ / medium: æœ€é«˜ç²¾åº¦ï¼ˆæ™‚é–“ã‹ã‹ã‚‹ï¼‰"
    )

    language_option = st.radio(
        "è¨€èª",
        ["è‡ªå‹•æ¤œå‡º", "æ—¥æœ¬èª", "è‹±èª"]
    )

    st.markdown("---")
    st.header("ğŸ“ å­—å¹•è¨­å®š")
    max_chars = st.slider(
        "1å­—å¹•ã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°",
        min_value=30,
        max_value=150,
        value=50,
        step=5,
        help="VREWç”¨ï¼š50æ–‡å­—ãŒãŠã™ã™ã‚"
    )

    st.markdown("---")
    st.markdown("### ãƒ¢ãƒ‡ãƒ«ç›®å®‰")
    st.markdown("""
    | ãƒ¢ãƒ‡ãƒ« | é€Ÿåº¦ | ç²¾åº¦ |
    |--------|------|------|
    | tiny | âš¡âš¡âš¡ | â­ |
    | base | âš¡âš¡ | â­â­ |
    | small | âš¡ | â­â­â­ |
    | medium | ğŸ¢ | â­â­â­â­ |
    """)

    st.markdown("---")
    st.header("ğŸŒ ç¿»è¨³è¨­å®š")

    enable_translation = st.checkbox(
        "æ—¥æœ¬èªç¿»è¨³ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
        value=False,
        help="è‹±èªã®æ–‡å­—èµ·ã“ã—çµæœã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¾ã™ï¼ˆClaude APIä½¿ç”¨ï¼‰"
    )

    if enable_translation:
        api_key = st.text_input(
            "Anthropic API Key",
            type="password",
            help="Claude APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        st.caption("â€» ç’°å¢ƒå¤‰æ•° ANTHROPIC_API_KEY ã§ã‚‚è¨­å®šå¯èƒ½")


def extract_audio(video_path: str, audio_path: str) -> None:
    """å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º"""
    stream = ffmpeg.input(video_path)
    stream = ffmpeg.output(
        stream.audio,
        audio_path,
        acodec="pcm_s16le",
        ar=16000,
        ac=1
    )
    ffmpeg.run(stream, overwrite_output=True, quiet=True)


def format_srt_timestamp(seconds: float) -> str:
    """ç§’æ•°ã‚’SRTå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ› (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def split_text_by_length(text: str, max_chars: int) -> list:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ€å¤§æ–‡å­—æ•°ã§åˆ†å‰²ï¼ˆå˜èªã®é€”ä¸­ã§åˆ‡ã‚‰ãªã„ï¼‰"""
    if len(text) <= max_chars:
        return [text]

    words = text.split()
    chunks = []
    current_chunk = ""

    for word in words:
        if len(current_chunk) + len(word) + 1 <= max_chars:
            current_chunk = current_chunk + " " + word if current_chunk else word
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = word

    if current_chunk:
        chunks.append(current_chunk)

    return chunks if chunks else [text]


def create_srt(segments, max_chars: int = 100) -> str:
    """Whisper ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ VREWäº’æ›SRTå½¢å¼ã‚’ç”Ÿæˆï¼ˆæ–‡å­—æ•°åˆ¶é™ä»˜ãï¼‰"""
    lines = []
    idx = 1

    for segment in segments:
        text = segment.text.strip()
        start_time = segment.start
        end_time = segment.end
        duration = end_time - start_time

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
        chunks = split_text_by_length(text, max_chars)
        chunk_duration = duration / len(chunks)

        for i, chunk in enumerate(chunks):
            chunk_start = start_time + (i * chunk_duration)
            chunk_end = start_time + ((i + 1) * chunk_duration)

            start_ts = format_srt_timestamp(chunk_start)
            end_ts = format_srt_timestamp(chunk_end)

            lines.append(str(idx))
            lines.append(f"{start_ts} --> {end_ts}")
            lines.append(chunk)
            lines.append("")
            idx += 1

    return "\n".join(lines)


def format_timestamp(seconds: float) -> str:
    """ç§’æ•°ã‚’ HH:MM:SS å½¢å¼ã«å¤‰æ›"""
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    return f"{h:02d}:{m:02d}:{s:02d}"


def create_timestamped_text(segments) -> str:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    lines = []
    for segment in segments:
        start = format_timestamp(segment.start)
        end = format_timestamp(segment.end)
        text = segment.text.strip()
        lines.append(f"[{start} - {end}] {text}")
    return "\n".join(lines)


def translate_segments_with_claude(segments_list: list, api_key: str, progress_callback=None) -> list:
    """Claude APIã‚’ä½¿ã£ã¦è‹±èªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³"""
    client = anthropic.Anthropic(api_key=api_key)
    translated_texts = []

    total = len(segments_list)
    for i, segment in enumerate(segments_list):
        original_text = segment.text.strip()

        if progress_callback:
            progress_callback(i + 1, total, original_text[:30] + "..." if len(original_text) > 30 else original_text)

        try:
            message = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1024,
                system="ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚è‹±èªã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚å­—å¹•ç”¨ãªã®ã§ç°¡æ½”ã«ã€‚ç¿»è¨³çµæœã®ã¿ã‚’å‡ºåŠ›ã—ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚",
                messages=[
                    {"role": "user", "content": f"æ¬¡ã®è‹±èªã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„:\n{original_text}"}
                ]
            )
            translated_text = message.content[0].text.strip()
            translated_texts.append(translated_text)
        except anthropic.RateLimitError:
            time.sleep(2)
            try:
                message = client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=1024,
                    system="ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚è‹±èªã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚å­—å¹•ç”¨ãªã®ã§ç°¡æ½”ã«ã€‚ç¿»è¨³çµæœã®ã¿ã‚’å‡ºåŠ›ã—ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚",
                    messages=[
                        {"role": "user", "content": f"æ¬¡ã®è‹±èªã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„:\n{original_text}"}
                    ]
                )
                translated_text = message.content[0].text.strip()
                translated_texts.append(translated_text)
            except Exception as e:
                translated_texts.append(f"[ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}]")
        except Exception as e:
            translated_texts.append(f"[ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}]")

        time.sleep(0.1)

    return translated_texts


def create_bilingual_srt(segments, translated_texts: list) -> str:
    """è‹±èªï¼ˆä¸Šï¼‰+ æ—¥æœ¬èªï¼ˆä¸‹ï¼‰ã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«SRTã‚’ç”Ÿæˆ"""
    lines = []

    for idx, (segment, ja_text) in enumerate(zip(segments, translated_texts), 1):
        start_ts = format_srt_timestamp(segment.start)
        end_ts = format_srt_timestamp(segment.end)
        en_text = segment.text.strip()

        lines.append(str(idx))
        lines.append(f"{start_ts} --> {end_ts}")
        lines.append(en_text)
        lines.append(ja_text)
        lines.append("")

    return "\n".join(lines)


# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
uploaded_file = st.file_uploader(
    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["mp4", "mov", "avi", "mkv", "flv", "webm", "m4v"]
)

if uploaded_file:
    st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¸ˆã¿: {uploaded_file.name}")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¡¨ç¤º
    file_size_mb = uploaded_file.size / (1024 * 1024)
    st.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.1f} MB")

    if st.button("ğŸš€ æ–‡å­—èµ·ã“ã—é–‹å§‹", type="primary"):
        # è¨€èªãƒãƒƒãƒ”ãƒ³ã‚°
        language_map = {
            "è‡ªå‹•æ¤œå‡º": None,
            "æ—¥æœ¬èª": "ja",
            "è‹±èª": "en"
        }
        selected_language = language_map[language_option]

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
            temp_audio_path = tmp_audio.name

        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_video:
            temp_video_path = tmp_video.name
            tmp_video.write(uploaded_file.getbuffer())

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³å£°æŠ½å‡º
            with st.spinner("ğŸ”Š éŸ³å£°ã‚’æŠ½å‡ºä¸­..."):
                extract_audio(temp_video_path, temp_audio_path)
            st.success("âœ… éŸ³å£°æŠ½å‡ºå®Œäº†")

            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
            with st.spinner(f"ğŸ¤– Whisper ãƒ¢ãƒ‡ãƒ« ({model_option}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                model = WhisperModel(model_option, device="cpu", compute_type="int8")
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

            # ã‚¹ãƒ†ãƒƒãƒ—3: æ–‡å­—èµ·ã“ã—
            with st.spinner("ğŸ“ æ–‡å­—èµ·ã“ã—ä¸­... (å‹•ç”»ã®é•·ã•ã«ã‚ˆã£ã¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)"):
                segments, info = model.transcribe(
                    temp_audio_path,
                    language=selected_language,
                    beam_size=5
                )
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ï¼ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãªã®ã§ï¼‰
                segments_list = list(segments)

            # æ¤œå‡ºè¨€èªã‚’è¡¨ç¤º
            if selected_language is None:
                st.info(f"ğŸŒ æ¤œå‡ºè¨€èª: {info.language} (ç¢ºç‡: {info.language_probability:.1%})")

            st.success("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")

            # ç¿»è¨³å‡¦ç†ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            translated_texts = None
            if enable_translation:
                actual_api_key = api_key if api_key else os.environ.get("ANTHROPIC_API_KEY")
                if actual_api_key:
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    def update_progress(current, total, text):
                        progress_bar.progress(current / total)
                        status_text.text(f"ğŸŒ ç¿»è¨³ä¸­... ({current}/{total}): {text}")

                    with st.spinner("ğŸŒ Claude ã§æ—¥æœ¬èªã«ç¿»è¨³ä¸­..."):
                        translated_texts = translate_segments_with_claude(
                            segments_list,
                            actual_api_key,
                            progress_callback=update_progress
                        )

                    progress_bar.empty()
                    status_text.empty()
                    st.success("âœ… ç¿»è¨³å®Œäº†ï¼")
                else:
                    st.warning("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")

            # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            full_text = "\n".join([seg.text.strip() for seg in segments_list])

            # SRT ä½œæˆï¼ˆæ–‡å­—æ•°åˆ¶é™ä»˜ãï¼‰
            srt_content = create_srt(segments_list, max_chars)

            # çµæœè¡¨ç¤º
            st.markdown("---")
            st.header("ğŸ“„ çµæœ")

            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            timestamped_text = create_timestamped_text(segments_list)

            # ã‚¿ãƒ–ã®æ§‹æˆã‚’ç¿»è¨³ã®æœ‰ç„¡ã§å¤‰æ›´
            if translated_texts:
                tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ", "â±ï¸ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã", "ğŸ¬ SRTå­—å¹•", "ğŸŒ ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«SRT", "ğŸ“Š ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°"])
            else:
                tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ", "â±ï¸ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã", "ğŸ¬ SRTå­—å¹•", "ğŸ“Š ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°"])

            with tab1:
                st.text_area("å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ", value=full_text, height=400)
                st.download_button(
                    label="ğŸ“¥ ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=full_text,
                    file_name=f"{Path(uploaded_file.name).stem}_transcription.txt",
                    mime="text/plain"
                )

            with tab2:
                st.markdown("ç¿»è¨³æ™‚ã«ä¾¿åˆ©ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãå½¢å¼ã§ã™")
                st.text_area("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆ", value=timestamped_text, height=400)
                st.download_button(
                    label="ğŸ“¥ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=timestamped_text,
                    file_name=f"{Path(uploaded_file.name).stem}_timestamped.txt",
                    mime="text/plain"
                )

            with tab3:
                st.markdown("**VREWå¯¾å¿œ** - ãã®ã¾ã¾VREWã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã™")
                st.text_area("SRTå½¢å¼", value=srt_content, height=400)
                st.download_button(
                    label="ğŸ“¥ SRT ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆVREWå¯¾å¿œï¼‰",
                    data=srt_content.encode('utf-8'),
                    file_name=f"{Path(uploaded_file.name).stem}_subtitles.srt",
                    mime="text/plain"
                )

            # ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«SRTã‚¿ãƒ–ï¼ˆç¿»è¨³æœ‰åŠ¹æ™‚ã®ã¿ï¼‰
            if translated_texts:
                with tab4:
                    bilingual_srt = create_bilingual_srt(segments_list, translated_texts)
                    st.markdown("**è‹±èªï¼ˆä¸Šï¼‰+ æ—¥æœ¬èªï¼ˆä¸‹ï¼‰ã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«å­—å¹•**")
                    st.markdown("VREW / VLC / YouTube ç­‰ã§ä½¿ç”¨å¯èƒ½")
                    st.text_area("ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«SRT", value=bilingual_srt, height=400)
                    st.download_button(
                        label="ğŸ“¥ ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«SRT ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=bilingual_srt.encode('utf-8'),
                        file_name=f"{Path(uploaded_file.name).stem}_bilingual.srt",
                        mime="text/plain"
                    )

                with tab5:
                    st.markdown(f"**ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°:** {len(segments_list)}")
                    for idx, (seg, ja_text) in enumerate(zip(segments_list, translated_texts)):
                        with st.expander(f"â±ï¸ {seg.start:.1f}s - {seg.end:.1f}s"):
                            st.write(f"**è‹±èª:** {seg.text.strip()}")
                            st.write(f"**æ—¥æœ¬èª:** {ja_text}")
            else:
                with tab4:
                    st.markdown(f"**ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°:** {len(segments_list)}")
                    for seg in segments_list:
                        with st.expander(f"â±ï¸ {seg.start:.1f}s - {seg.end:.1f}s"):
                            st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆ:** {seg.text.strip()}")

        except ffmpeg.Error as e:
            st.error(f"âŒ éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: FFmpeg ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            st.code("brew install ffmpeg  # macOS ã®å ´åˆ")

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("*Powered by [faster-whisper](https://github.com/SYSTRAN/faster-whisper)*")
